#include "SceneFinder.h"
#include <cstdlib>

#include <iostream>
#include <algorithm>
#include <fstream>
#include <chrono>

#include <ISM/MathHelper.hpp>
#include <ISM/RecognitionResult.hpp>
#include <ISM/Object.hpp>

#include <scene_recognition_rviz_plugin/Visualizer.hpp> 

extern std::ofstream timesFile;
extern std::ofstream recogResultsFile;

namespace ASR {

  SceneFinder::SceneFinder(Eigen::Vector2f start, Eigen::Vector2f end) {

    ros::NodeHandle n("~");
	
    //double alpha_R, alpha_C, alpha_E;
    double alpha_R, alpha_C;
    n.getParam("alpha_R", alpha_R);
    n.getParam("alpha_C", alpha_C);
    //n.getParam("alpha_E", alpha_E);

    if(!n.getParam("quad_pan_deg", quad_pan_deg))
      quad_pan_deg = 5;

    if(!n.getParam("quad_tilt_deg", quad_tilt_deg))
      quad_tilt_deg = 5;

    if(!n.getParam("sensitivity", sensitivity))
      sensitivity = 0.05;

    if(!n.getParam("dbfilename", dbfilename))
      dbfilename = "/home/staff/meissner/devel/ros/stacks/ilcasRosPkg/branches/renoreckling/recognition/scene_recognition/recordings/pascal/rcord.sqlite.smacksTest";

    if(!n.getParam("keepUnfoundObjectVotesViz", keepUnfoundObjectVotesViz))
      keepUnfoundObjectVotesViz = true;

    if(!n.getParam("enableEvaluation", enableEvaluation))
      enableEvaluation = false;

    Eigen::Vector2f delta(quad_pan_deg, quad_tilt_deg);

    recognizer = ISM::RecognizerPtr(new ISM::Recognizer(dbfilename, sensitivity));
    tableHelper = ISM::TableHelperPtr(new ISM::TableHelper(dbfilename));

    if(tableHelper->getModelPatternNames().empty()){
      
      ROS_ERROR("Loaded empty sql table into ism.");
      std::exit(1);

    }      

    //Just extract those objects from table, that are non-reference objects.
    mObjectsInScenes = tableHelper->getObjectTypesAndIds();
    for(std::set<std::pair<std::string, std::string> >::iterator objectIterator = mObjectsInScenes.begin(); objectIterator != mObjectsInScenes.end(); objectIterator++) {
      
      if(objectIterator->first.find("_sub") != std::string::npos) {
	mObjectsInScenes.erase(objectIterator);
	objectIterator = mObjectsInScenes.begin();
      }

    }
 
    for(auto& object : mObjectsInScenes)
      ROS_INFO_STREAM("Objects in model: " << std::endl << object.first << " " << object.second << std::endl);

    //Extract all pattern names from database.
    rootPatternNames = tableHelper->getModelPatternNames();    

    for(std::vector<std::string>::iterator patternIterator = rootPatternNames.begin(); patternIterator != rootPatternNames.end(); patternIterator++) {
      
      if(patternIterator->find("_sub") != std::string::npos) {
	rootPatternNames.erase(patternIterator);
	patternIterator = rootPatternNames.begin();
      }

    }
    
    grid = QuadGridPtr(new QuadGrid(start, end, delta, mObjectsInScenes, alpha_R, alpha_C));
    objectSet = ISM::ObjectSetPtr(new ISM::ObjectSet());

    for(auto& patternName : tableHelper->getModelPatternNames()) {
      
      std::set<std::pair<std::string, std::string> > objectsInPattern = tableHelper->getObjectTypesAndIdsBelongingToPattern(patternName);
      
      ISM::ObjectToVoteMap objectVotes = tableHelper->getVoteSpecifiersForPatternAndObjects(patternName, objectsInPattern);

      votes[patternName] = objectVotes;

    }

  }

  SceneFinder::~SceneFinder() {}

  QuadGridPtr SceneFinder::getGrid(){
    
    return grid;

  }
  
  std::list<std::string> SceneFinder::getRootPatterns() {
    
    return std::list<std::string>(rootPatternNames.begin(),rootPatternNames.end());

  }

  std::vector<ISM::RecognitionResultPtr> SceneFinder::findScenes(const pbd_msgs::PbdObject::ConstPtr& msg, geometry_msgs::Pose p, double filterThreshold, int resultsPerPattern){
    
    //Represent result from object recognition systems in ism recognition manner.
    ISM::ObjectPtr newObject(new ISM::Object(msg->type, new ISM::Pose(new ISM::Point(p.position.x, p.position.y, p.position.z), new ISM::Quaternion((double)p.orientation.w, (double)p.orientation.x, (double)p.orientation.y, (double)p.orientation.z)), msg->identifier));

    //Update quad grid exploration info, if input object has been previously unfound.
    if(mFoundObjects.find(std::make_pair(newObject->getType(), newObject->getId())) == mFoundObjects.end()) {

      ROS_INFO("Previously unfound object with type = %s and id = %s is localized at (%.2f, %.2f, %.2f) resp. in left img: (%d, %d).\n", newObject->getType().c_str(), newObject->getId().c_str(), newObject->getPosePtr()->getPointPtr()->getX(), newObject->getPosePtr()->getPointPtr()->getY(), newObject->getPosePtr()->getPointPtr()->getZ(), msg->leftImageCentroid[0], msg->leftImageCentroid[1]);
	  
      //Mark quad as explored for this type of object.
      grid->markAsExplored(newObject->getType(), newObject->getId());

      //Add previously not detected object to input for ism scene recognition.
      objectSet->insert(newObject);

    }
    //Replace pose of object already detected in the past.
    /*else {
      
      for(ISM::ObjectPtr& object : objectSet->objects)
	if(!(object->type.compare(newObject->type)) && !(object->observedId.compare(newObject->observedId)))
	  object->pose = ISM::PosePtr(new ISM::Pose(*(newObject->pose)));

	  }*/

    //std::cout << "Current ObjectSet " << objectSet << std::endl;

    ISM::ObjectSetPtr tmpObjectSet(new ISM::ObjectSet(*objectSet));
    
    std::vector<ISM::RecognitionResultPtr> recognitionResults;
    
    //Updating scene hypotheses just when previously unfound object is detected.
    //Currently we can get here in an infinite loop when doing otherwise
    //Situation: We are at a position where we detect an object in every run and therefore reset our scene hypotheses. But we never change ptu orientation since this hypotheses give us no clue on positions of unfound objects as all potential positions are already marked as explored.
    if(mFoundObjects.find(std::make_pair(newObject->getType(), newObject->getId())) == mFoundObjects.end()) {
    
      //EVALUATION
      std::chrono::time_point<std::chrono::system_clock> start, end;
      start = std::chrono::system_clock::now();
      //EVALUATION

      //For every scene type (pattern name), return the root of the recognized scene model rated best of the given object set (concerning its confidence).
      recognitionResults = recognizer->recognizePattern(tmpObjectSet, filterThreshold, resultsPerPattern);

      //EVALUATION
      end = std::chrono::system_clock::now();
      std::chrono::duration<double> elapsed_seconds = end-start;

      timesFile << "recognizePattern: " << elapsed_seconds.count() << " " << ros::Time::now().toNSec() << std::endl;
      recogResultsFile << "recognizePattern: " << elapsed_seconds.count() << " " << ros::Time::now().toNSec() << std::endl;
      //EVALUATION

      //Sort in ascending order using recognition results confidence.
      std::sort(recognitionResults.begin(), recognitionResults.end(), lessConfidence);

      //the same scene to be print out beneath for the same scene over and over again.
      mFoundObjects.insert(std::make_pair(newObject->getType(), newObject->getId()));
	
    }

    return recognitionResults;
       
  }

  std::vector<ISM::RecognitionResultPtr> SceneFinder::findScenes(ISM::ObjectSetPtr objectSet, double filterThreshold, int resultsPerPattern) {
   
    ISM::ObjectSetPtr tmpObjectSet(new ISM::ObjectSet(*objectSet));

    //For every scene type (pattern name), return the root of the recognized scene model rated best of the given object set (concerning its confidence).
    std::vector<ISM::RecognitionResultPtr> recognitionResults = recognizer->recognizePattern(tmpObjectSet, filterThreshold, resultsPerPattern);

    //Sort in ascending order using recognition results confidence.
    std::sort(recognitionResults.begin(), recognitionResults.end(), lessConfidence);

    return recognitionResults;

  }

  bool SceneFinder::lessConfidence(ISM::RecognitionResultPtr i,ISM::RecognitionResultPtr j) {
    return (i->getConfidence() < j->getConfidence());

  }

  void SceneFinder::deleteUnfoundObjectsPoseHypotheses() {
    
    grid->clearObjectPresenceCounters();
    grid->clearSamples();    
    grid->clearUnfoundObjects();
    
  }

  void SceneFinder::updateUnfoundObjectsPoseHypotheses(ISM::RecognitionResultPtr reference) {
    
    deleteUnfoundObjectsPoseHypotheses();

    //EVALUATION
    std::chrono::time_point<std::chrono::system_clock> start, end;
    start = std::chrono::system_clock::now();
    //EVALUATION

    //We have already detected a scene
    if(reference) {

      //Calculate absolute pose of unknown objects using detected scene reference. We call this function just once (therefore using weight=1) as we only consider one hypotheses.
      ISM::PosePtr tmp = reference->getReferencePosePtr();
      calcUnfoundPoses(tmp, reference->getPatternName(), 1);

    }

    //EVALUATION
    end = std::chrono::system_clock::now();
    std::chrono::duration<double> elapsed_seconds = end-start;

    timesFile <<  "poseHypothesesCalc: " << elapsed_seconds.count() << " " << ros::Time::now().toNSec() << std::endl;    
    recogResultsFile <<  "poseHypothesesCalc: " << elapsed_seconds.count() << " " << ros::Time::now().toNSec() << std::endl;    
    //EVALUATION

  }

  void SceneFinder::calcUnfoundPoses(ISM::PosePtr& referencePose, std::string patternName, unsigned int weight) {

    if(!referencePose) {
      
      ROS_ERROR("Not initialized pointer as reference in calcUnfoundPoses()");
      std::exit(1);

    }

    //std::cout << "Searching objects for pattern " << patternName << "using pose " << referencePose << " and weight " << weight << std::endl; 

    //Get all reference and non-reference objects for given reference.
    std::set<std::pair<std::string, std::string> > objectsInPattern = tableHelper->getObjectTypesAndIdsBelongingToPattern(patternName);

    /*std::cout << "The following objects are associated to this pattern." << std::endl;

    for(auto& object : objectsInPattern){

      std::cout << object.first <<  " " << object.second << std::endl;

      }*/

    for(auto& object : objectsInPattern) {

      //std::cout << "Taking votes for object " << object.first << std::endl; 

      //Look whether we have an unfound object (reference object can never be found as they do not exist). Else ignore vote, as we already know its pose.
      if(mFoundObjects.find(std::make_pair(object.first, object.second)) == mFoundObjects.end()){

	//Get all votes that fit to combination of this reference (to reference and non-reference objects) and unfound object.
	std::vector<ISM::VoteSpecifierPtr> specifiers = votes.at(patternName).at(object.first).at(object.second);

	//If we have a reference object, search under it for unknown objects
	if(object.first.find("_sub") != std::string::npos) {

	  //Go through all fitting votes.
	  for(auto& specifier: specifiers) {
		
	    //Calculate absolute pose of unknown object
	    ISM::PointPtr absPosition = ISM::MathHelper::getOriginPoint(referencePose, specifier->refToObjectQuat, specifier->radius);
	    //Calculate full pose for next call of this function.
	    ISM::PosePtr absPose = ISM::MathHelper::getReferencePose(referencePose, absPosition, specifier->refToObjectPoseQuat);

	    //Check whether this reference object is identical to the reference of the ism in which it is object. 
	    if(ISM::Recognizer::poseEqual(referencePose, absPose)) {

	      //Every single vote for a hypotheses in specifier has to be repreated for all redundancies in lower parts of the tree.
	      unsigned int numberOfHypotheses = weight * specifiers.size();
	      
	      //One level higher in the scene model hierarchy, object pose hypotheses should be replicated for every vote in specifiers as well as every time this function would have been called. Reference object in this ism gets reference of next higher ism.
	      calcUnfoundPoses(absPose, object.first, numberOfHypotheses);
	      
	      //If position of this object in scene is equal to pose of reference, then it has been chosen as reference and its pose will be equal to the reference through all votes. So we do not need to process any other votes here.
	      break;
		      
	    }
	    //This reference object is not equal to the reference of the ism in which it resides.
	    else{
	      
	      //One level higher in the scene model hierarchy, object pose hypotheses should be replicated for every time this function would have been called.
	      calcUnfoundPoses(absPose, object.first, weight);

	    }

	  }

	}
	//We have a non-reference object that we have not found and save its position.
	else {

	  //Go through all fitting votes.
	  for(auto& specifier: specifiers){

	    //Calculate absolute pose of unknown object
	    ISM::PointPtr absPosition = ISM::MathHelper::getOriginPoint(referencePose, specifier->refToObjectQuat, specifier->radius);
	    ISM::PosePtr absPose = ISM::MathHelper::getReferencePose(referencePose, absPosition, specifier->refToObjectPoseQuat);
	    
	    //Visualizer::pointToSphere(absPosition, 1,1,1,"anywoulddo",2);
	    //ROS_DEBUG_STREAM("absPositions: " << absPosition <<  std::endl);

	    //Check whether this non-reference object is identical to the reference of the ism in which it is object. 
	    if(ISM::Recognizer::poseEqual(referencePose, absPose)){

	      //Every single vote for a hypotheses in specifier has to be repreated for all redundancies in lower parts of the tree.
	      unsigned int numberOfHypotheses = weight * specifiers.size();

	      //As all votes are identical, just skip all further votes and insert points for all of them at once.
	      grid->insertPoint(specifier->objectType, specifier->observedId, Eigen::Vector3f(absPosition->getX(), absPosition->getY(), absPosition->getZ()), Eigen::Vector3f(referencePose->getPointPtr()->getX(), referencePose->getPointPtr()->getY(), referencePose->getPointPtr()->getZ()), numberOfHypotheses);
	      
	      //Stop going through all further votes.
	      break;

	    }
	    //This non-reference object is not equal to the reference of the ism in which it resides.
	    else {
	      
	      //Insert absolute unkown object pose into tesselated sphere quad just for one vote, but considering all redundancies of the isms in lover parts of the tree
	      grid->insertPoint(specifier->objectType, specifier->observedId, Eigen::Vector3f(absPosition->getX(), absPosition->getY(), absPosition->getZ()), Eigen::Vector3f(referencePose->getPointPtr()->getX(), referencePose->getPointPtr()->getY(), referencePose->getPointPtr()->getZ()), weight);

	    }
    
	  }

	  //Save that we found this object as missing in our currently considered scene hypotheses.
	  grid->mUnfoundObjects.insert(std::make_pair(object.first, object.second));

	}

      }      

    }
	
  }

  //finds best view based
  View SceneFinder::nextBestView(Eigen::Vector2f currentViewCenter, Eigen::Vector2f cameraFoV) {

    //EVALUATION
    std::chrono::time_point<std::chrono::system_clock> start, end;
    start = std::chrono::system_clock::now();
    //EVALUATION

    View bestView = grid->bestView2(currentViewCenter,cameraFoV);

    //EVALUATION
    end = std::chrono::system_clock::now();
    std::chrono::duration<double> elapsed_seconds = end-start;

    timesFile <<  "nextBestViewCalc: " << elapsed_seconds.count() << " " << ros::Time::now().toNSec() << std::endl;
    recogResultsFile <<  "nextBestViewCalc: " << elapsed_seconds.count() << " " << ros::Time::now().toNSec() << std::endl;
    //EVALUATION

    return bestView;

  }

  bool SceneFinder::isObjectInScenes(std::string objectType, std::string objectIdentifier) {
    return mObjectsInScenes.find(std::make_pair(objectType, objectIdentifier)) != mObjectsInScenes.end();
  }

  bool SceneFinder::areThereUnfoundObjects(){
    
    return mFoundObjects.size() != mObjectsInScenes.size();

  }
  
  //We end processing when view with best score has a score under a given threshold.
  void SceneFinder::update(View visited) {

    if (visited.valid) {
      
      //!TODO: Here we should not take all objects as well.
      for(auto& object : mObjectsInScenes)
	grid->markFoVAsExplored(visited, object.first, object.second);

      //Delete all data in this view concerning unfound object poses if any exist (there are not any during initial search).
      grid->clearObjectPresenceCountersFoV(visited);
      if(!keepUnfoundObjectVotesViz)
	grid->clearSamplesFoV(visited);

    }

  }

}
